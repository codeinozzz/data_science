{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div\n",
    "  style=\"\n",
    "    background-color: #f0f0f0;\n",
    "    color:rgb(56, 56, 56);\n",
    "    padding: 8px;\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    gap: 100px;\n",
    "  \"\n",
    ">\n",
    "  <img src=\"./images/brand.svg\" style=\"max-height: 80px;\">\n",
    "  <strong>\n",
    "    AI Saga: Data Science and Machine Learning</br>\n",
    "    2.lab.1. Wisconsin Cancer Classification\n",
    "  </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "You will continue working with the Wisconsin Diagnostic Cancer Dataset, but this time implementing classification models using scikit-learn.\n",
    "\n",
    "The dataset includes:\n",
    "- 569 instances\n",
    "- 30 numeric features computed from the cell nuclei present in the image\n",
    "- Binary classification: **Malignant** or **Benign** diagnosis\n",
    "\n",
    "### Description\n",
    "\n",
    "Your task is to implement logistic regression using scikit-learn to:\n",
    "\n",
    "- Implement logistic regression using all features\n",
    "- Find the best performing pair of features for classification\n",
    "- Compare the accuracy between using all features vs. the best pair\n",
    "- Visualize the decision boundary for the best feature pair\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "- A **ipynb** (Jupyter Notebook) file called **wisconsin-cancer-classification.ipynb**\n",
    "- The notebook should include visualizations of the decision boundaries\n",
    "- A clear comparison of performance between using all features vs. the best pair\n",
    "- Use the provided template as a starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Cáncer con Scikit-Learn\n",
    "\n",
    ">nota: iniciare nuevamente las librerias para no arruinar o cambiar mucho la impelmentacion anteriror\n",
    "\n",
    "Cargar dataset de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "X = cancer_data.data\n",
    "y = cancer_data.target\n",
    "feature_names = cancer_data.feature_names\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reprocesamiento con Scikit-Learn\n",
    "\n",
    "\n",
    "aqui pues explico lo que entendi del codigo pues me base muchoe en el propuesto en clase\n",
    "\n",
    "- train_test_split() divide automáticamente los datos aleatoriamente\n",
    "-  StandardScaler() calcula la media y desviación estándar del entrenamiento con fit_transform() y luego aplica la misma transformación al test con transform().\n",
    "\n",
    "\n",
    "\n",
    "aqui basicamente lo qeu hhacemos es La normalización  porque las mediciones en este caso tienen escalas muy diferentes en todas las varibels o coliumnas tipo el radio promedio puede ser 14.0 mientras que la dimensión  es 0.06 entonces Sin esta estandarización, las características con valores más grandes dominarían por asi decir  la clasificación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# división de datos con scikit-learn\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# Normalización con scikit-learn\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística con Todas las Características\n",
    "\n",
    "\n",
    "- LogisticRegression() crea el modelo\n",
    "- fit() entrena con los datos normalizados, \n",
    "- predict() genera las clasificaciones y accuracy_score() calcula el porcentaje de todos los  aciertos.\n",
    "\n",
    "aqui pues loq eu ahcemos es considerar todas  las medicioones para  determinar los tumores osea sis es maligno o benigno, cada caracteristica va a recibir un peso para indicar su importancia en la decision del final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all_features = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_all_features.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_all = model_all_features.predict(X_test_scaled)\n",
    "accuracy_all = accuracy_score(y_test, y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busqueda del Mejor Par de Características\n",
    "\n",
    "- combinations() genera todas las parejas posibles. \n",
    "- El bucle entrena en un LogisticRegression() independiente para cada par usando indexación de arrays (X[:, [idx1, idx2]]) para seleccionar solo 2 columnas.\n",
    "\n",
    "\n",
    "aqui estos metodos basicamente lo qeu vamos hacer es evlauar 435 combinaciones posibles con los pares de caracteristicas para de esa manera saber cuales son las dos mediciones mas efectivas para distingir entre los tumores, en este caso son worst radius/ worst fractal dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# busqueda  usando scikit-learn\n",
    "best_accuracy = 0\n",
    "best_pair = None\n",
    "best_indices = None\n",
    "\n",
    "for idx1, idx2 in combinations(range(X.shape[1]), 2):\n",
    "    X_train_pair = X_train_scaled[:, [idx1, idx2]]\n",
    "    X_test_pair = X_test_scaled[:, [idx1, idx2]]\n",
    "\n",
    "    model_pair = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model_pair.fit(X_train_pair, y_train)\n",
    "\n",
    "    y_pred_pair = model_pair.predict(X_test_pair)\n",
    "    accuracy_pair = accuracy_score(y_test, y_pred_pair)\n",
    "\n",
    "    if accuracy_pair > best_accuracy:\n",
    "        best_accuracy = accuracy_pair\n",
    "        best_pair = (feature_names[idx1], feature_names[idx2])\n",
    "        best_indices = (idx1, idx2)\n",
    "\n",
    "# aqui se entrena al  modelo final con mejor par\n",
    "X_train_best = X_train_scaled[:, list(best_indices)]\n",
    "X_test_best = X_test_scaled[:, list(best_indices)]\n",
    "model_best_pair = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_best_pair.fit(X_train_best, y_train)\n",
    "\n",
    "print(f\"Mejor par encontrado: {best_pair}\")\n",
    "print(f\"Precisión del mejor par: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Visualizacion de la Frontera de Decision\n",
    "\n",
    "\n",
    "- plt.scatter() con indexación booleana (y_train == 0) separa los puntos por color. \n",
    "- np.meshgrid() crea una rejilla de puntos, \n",
    "- model.predict() clasifica cada punto de la rejilla y plt.contour() dibuja la línea donde va a cambiar  la predicción.\n",
    "\n",
    "- La gráfica muestra una clara  separación  entre los puntos rojos y azules. Los puntos rojos (tumores malignos) tienden a concentrarse en la región superior derech lo que nos indica que los tumores malignos tienen valores más altos tanto en \"worst radius\" como en \"worst fractal dimension\"  mientra que \n",
    "\n",
    "- Los puntos azules, qlos tumores benignos, se agrupan en la zona inferior izquierda indicando que tienen células más pequeñas y de una forma regular. La línea verde en este caso va  a ser el límite que divide los resultados todo lo que queda arriba y a la derecha de ella se clasifica como tumor maligno, mientras que lo que está abajo y a la izquierda se consideraun tumor  benigno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    X_train_best[y_train == 0, 0],\n",
    "    X_train_best[y_train == 0, 1],\n",
    "    color=\"red\",\n",
    "    label=\"Maligno\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "plt.scatter(\n",
    "    X_train_best[y_train == 1, 0],\n",
    "    X_train_best[y_train == 1, 1],\n",
    "    color=\"blue\",\n",
    "    label=\"Benigno\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "\n",
    "# Creacion frontera de decisión\n",
    "h = 0.02\n",
    "x_min, x_max = X_train_best[:, 0].min() - 1, X_train_best[:, 0].max() + 1\n",
    "y_min, y_max = X_train_best[:, 1].min() - 1, X_train_best[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = model_best_pair.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contour(xx, yy, Z, levels=[0.5], colors=\"green\", linewidths=2, linestyles=\"--\")\n",
    "plt.xlabel(best_pair[0])\n",
    "plt.ylabel(best_pair[1])\n",
    "plt.title(f\"Frontera de Decisión - {best_pair[0]} vs {best_pair[1]}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de Modelos\n",
    "\n",
    "\n",
    "- rich.Table() crea una tabla formateada para mostrar los resultados de manera clara, comparando las precisiones obtenidas con accuracy_score().\n",
    "\n",
    "al anlizar la tabla podemos decir que: \n",
    "\n",
    "- el modelo que usa solo 2 características logra mayor precisión (98.25%) que el modelo con 30 características (97.37%) lo ques sugiere que las mediciones \"worst radius\" y \"worst fractal dimension\" si tienen la  información más crítica para distinguir o definir  entre tumores malignos y benignos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_table = Table(\n",
    "    title=\"Comparación de Modelos con Scikit-Learn\",\n",
    "    show_header=True,\n",
    "    header_style=\"bold\",\n",
    ")\n",
    "\n",
    "comparison_table.add_column(\"Modelo\", justify=\"left\", style=\"cyan\")\n",
    "comparison_table.add_column(\"Características\", justify=\"center\", style=\"yellow\")\n",
    "comparison_table.add_column(\"Precisión\", justify=\"right\", style=\"green\")\n",
    "\n",
    "comparison_table.add_row(\n",
    "    \"Todas las características\", f\"{X.shape[1]} características\", f\"{accuracy_all:.4f}\"\n",
    ")\n",
    "\n",
    "comparison_table.add_row(\n",
    "    \"Mejor par de características\",\n",
    "    f\"{best_pair[0][:20]}...\\n{best_pair[1][:20]}...\",\n",
    "    f\"{best_accuracy:.4f}\",\n",
    ")\n",
    "\n",
    "console.print(comparison_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anlisis final\n",
    "\n",
    "usar solo 2 características del tumor (tamaño e irregularidad de la forma) funcionó mejor que usar las 30 disponibles pues usando  regresión logística.graficamos los resultados, vimos una línea muy clara que separa los tumores malignos (puntos rojos) de los benignos (puntos azules), confirmando que estas dos medidas fueron las mas criticas en  los patrones reales de la enfermedad. Las implicaciones son muy prácticas: análisis más rápidos,fáciles de interpretar en caso de  uso en la medicina , y el uso de la libreria simplifico muchisimo mas el proceso la regresioin  y aplicacion mateematica .en resumen si se obtiene caracteristicas escneciales se puede con ese enfoque tener un mejor anaslisis para sitribucion de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
