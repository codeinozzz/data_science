{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div\n",
    "  style=\"\n",
    "    background-color: #f0f0f0;\n",
    "    color:rgb(56, 56, 56);\n",
    "    padding: 8px;\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    gap: 100px;\n",
    "  \"\n",
    ">\n",
    "  <img src=\"./images/brand.svg\" style=\"max-height: 80px;\">\n",
    "  <strong>\n",
    "    AI Saga: Data Science and Machine Learning</br>\n",
    "    3.lab.1. Wisconsin Cancer Classification - Neural Networks\n",
    "  </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# week 3 - Neural Networks for Classification: Wisconsin Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# nota  esto es momentaneo para el proximo lab planneo unificaar los inports  estoy a la  espera del merge requeste anteriror  para hacer un rebase\n",
    "# y unificar los imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de semillas\n",
    "\n",
    "- `torch.manual_seed(42):` Fija la semilla aleatoria de PyTorch\n",
    "- `np.random.seed(42):` Fija la semilla aleatoria de NumP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aqui  meramente cargamos dataset, con el `data = load_breast_cancer()`, luego extraemos las caracteristicas por tumor para X y y solo son etiquetas 0 maligno, 2 benigno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data  # 30 características numéricas\n",
    "y = data.target  # 0: maligno, 1: benigno\n",
    "feature_names = data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacion \n",
    "\n",
    "- `StandardScaler():` Crea un normalizador de datos\n",
    "- `fit_transform():` Normaliza las 30 características a media=0, desviación=1\n",
    "\n",
    "aqui la normalizacion pues como es comun es por que el dataset tiene escalas bastante diferentes , esto hace que se tenga encuenta todas las caracteristica \n",
    "\n",
    "\n",
    "- test_size=0.2: 80% para entrenar, 20% para probar\n",
    "- random_state=42: usa la semilla para división reproducible,  es decir cadaa ejcucion ser igual en la reparticion de datos\n",
    "- stratify=y: Mantiene la misma proporción de benignos/malignos en ambos conjuntos\n",
    "\n",
    "\n",
    "luego simpelemnte transformamos los arrays a tensores  por que la lib reria trabaja con tensores mas no con arrays, en PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# División estratificada para mantener proporciones de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Conversión a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## red neuronal\n",
    "\n",
    "- class BreastCancerNet:  red neuronal  para cáncer de mama\n",
    "- nn.Module: Hereda funcionalidades básicas de PyTorch\n",
    "\n",
    "\n",
    "### Parámetros de entrada:\n",
    "\n",
    "input_dim=30: Entrada de 30 características\n",
    "hidden_dims=[64, 32, 16]: Capas ocultas de 64→32→16 neuronas\n",
    "output_dim=2: Sabenigno/maligno\n",
    "dropout_rate=0.3: 30% de neuronas se apagan para evitar un  sobreajuste\n",
    "\n",
    "### loop \n",
    "\n",
    "Linear: Conexiones entre neuronas (30→64→32→16→2)\n",
    "BatchNorm: Normaliza datos entre capas\n",
    "ReLU: Función de activación (convierte negativos en 0)\n",
    "Dropout: Apaga 30% de neuronas aleatoriamente\n",
    "\n",
    "\n",
    "aqui en esta clase creamos  una red neuronal completa que recibe 30 características de un tumor y va a predecir si es benigno o maligno, usando el dropout  para evitar sobreajuste y mejorar el aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastCancerNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim=30, hidden_dims=[64, 32, 16], output_dim=2, dropout_rate=0.3\n",
    "    ):\n",
    "        super(BreastCancerNet, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        # Capas ocultas con BatchNorm y Dropout\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend(\n",
    "                [\n",
    "                    nn.Linear(prev_dim, hidden_dim),\n",
    "                    nn.BatchNorm1d(hidden_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(dropout_rate),\n",
    "                ]\n",
    "            )\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        # Capa de salida\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuracion del entrenamiento \n",
    "\n",
    "- ### model = BreastCancerNet()\n",
    "\n",
    "Creamo  una instancia de la red neuronal que definimos antes\n",
    "Inicializa todos los pesos y capas automáticamente\n",
    "\n",
    "- ### criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "Define la función de pérdida para clasificación\n",
    "Mide qué tan equivocadas están las predicciones del modelo\n",
    "\n",
    "- ### optimizer = optim.Adam(...)\n",
    "\n",
    "- Adam: Algoritmo que actualiza los pesos del modelo\n",
    "- lr=0.001: Velocidad de aprendizaje \n",
    "- weight_decay=1e-4: Regularización para evitar sobreajuste\n",
    "\n",
    "\n",
    "en resumen el model sirve como el cerebro es decir aqui va aprender , el criterion sera el que evalue si los resultados son correctos o no, y el optimizer hara las mejoras en base a los resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BreastCancerNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop para el aprendizaje \n",
    "\n",
    "\n",
    "### varaibles\n",
    "\n",
    "\n",
    "- epochs = 500: vera los datos 500 veces\n",
    "- loss_history: lista para guardar errores en cada época\n",
    "- accuracy_history: lista para guardar precisión cada 10 épocas\n",
    "\n",
    "\n",
    "### Ciclo for\n",
    "\n",
    "- Forward: los datos pasan por la red  y basicamente  obtienen las predicciones\n",
    "- Loss: compara predicciones con respuestas correctas\n",
    "- Backward: calcula cómo ajustar cada peso\n",
    "- Step: aplica los ajustes a los pesos\n",
    "\n",
    "### Condicional\n",
    "\n",
    "\n",
    "basicamente el condicional dentro del ciiclo `if (epoch + 1) % 10 == 0:` lo que hace es que cada 10 epocas evalua que tan bien va el aprendizaje , en ese momento activa las isguientes funciones:\n",
    "\n",
    "- model.eval(): Activa todas las neuronas para la prueba\n",
    "- torch.no_grad(): sirve para no guardar informaciona dicionbal usi no solo resultados lo que ahorra memoria\n",
    "\n",
    "\n",
    "en conclusion para este apartado se entrena la red neuronal con 500 iteraciones, donde se va aprendiendoo sobre la marcha me explico va aprendindo de lso errores y se va ajustando en los pesos para mejorar las predicciones, guardando cada progresos para el analisi posterior al realizado\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_history.append(loss.item())\n",
    "\n",
    "    # Calcular accuracy cada 10 épocas\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_outputs = model(X_train_tensor)\n",
    "            _, predicted = torch.max(train_outputs, 1)\n",
    "            accuracy = (predicted == y_train_tensor).float().mean()\n",
    "            accuracy_history.append(accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion final del modelo \n",
    "\n",
    "- model.eval(): Pone el modelo en modo evaluación es deecir activa todas las neuronas\n",
    "- torch.max(): benigno/maligno, toma la más alta como predicción\n",
    "- numpy(): Convierte tensores a arrays para usar con sklearn\n",
    "\n",
    "### Calculo de metricas:\n",
    "\n",
    "- Accuracy: da el porcentaje  de predicciones correctas totales\n",
    "- Precision: de los que dijo \"maligno\",nos dice  ¿cuántos realmente lo eran?\n",
    "- Recall: de todos los malignos reales, ¿cuántos detectó?\n",
    "\n",
    "\n",
    "### F1: Promedio de precision y recall\n",
    "\n",
    "- Train: funcion para ver que tambien se  meoriza  los datos de entrenamiento\n",
    "- Test: Qué tan bien se generaliza a datos nuevos \n",
    "\n",
    "\n",
    "en conclusion en este fragmaento evaluamos el rendimeinto fiinal de la red neuronal que entrenamos, esto pues calacualdo multiples metricas tento en datoos de eentrenamiento como los de  prueba lo que nos permite saber qu tan bien clasificados estan los tumoeres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Predicciones de entrenamiento\n",
    "    train_outputs = model(X_train_tensor)\n",
    "    _, y_train_pred = torch.max(train_outputs, 1)\n",
    "    y_train_pred = y_train_pred.numpy()\n",
    "\n",
    "    # Predicciones de prueba\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, y_test_pred = torch.max(test_outputs, 1)\n",
    "    y_test_pred = y_test_pred.numpy()\n",
    "\n",
    "# Cálculo de métricas\n",
    "acc_train_nn = accuracy_score(y_train, y_train_pred)\n",
    "acc_test_nn = accuracy_score(y_test, y_test_pred)\n",
    "prec_train_nn = precision_score(y_train, y_train_pred)\n",
    "prec_test_nn = precision_score(y_test, y_test_pred)\n",
    "recall_train_nn = recall_score(y_train, y_train_pred)\n",
    "recall_test_nn = recall_score(y_test, y_test_pred)\n",
    "f1_train_nn = f1_score(y_train, y_train_pred)\n",
    "f1_test_nn = f1_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados previos\n",
    "\n",
    "\n",
    "- acc_log_all = 0.9737     \n",
    "- acc_log_2feat = 0.9825    \n",
    "\n",
    "estas variables implemnte guardan los resultados anterirores paaracomparar con la red neuronal en este caso pues en el anterior resultado se evaluo con las mejores caracteristeicas pues se haran uso de eestas 2 no mas\n",
    "\n",
    "### Caracteristicas \n",
    "\n",
    "aqui meramente  se buscan en lso indices las 2 caracteristicas especificas\n",
    "\n",
    "- worst_radius_idx: Radio del tumor en su peor zona\n",
    "- worst_fractal_idx: Complejidad de la forma del tumor\n",
    "\n",
    "luego extraemos esas mismas 2 caracteristicas tanto del entrenamiento como de la prueba \n",
    "\n",
    "\n",
    " - X_test_2feat\n",
    "- X_train_2feat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados anteriores establecidos\n",
    "acc_log_all = 0.9737\n",
    "acc_log_2feat = 0.9825\n",
    "\n",
    "# Preparamos datos para red neuronal con 2 características\n",
    "worst_radius_idx = np.where(feature_names == \"worst radius\")[0][0]\n",
    "worst_fractal_idx = np.where(feature_names == \"worst fractal dimension\")[0][0]\n",
    "X_train_2feat = X_train[:, [worst_radius_idx, worst_fractal_idx]]\n",
    "X_test_2feat = X_test[:, [worst_radius_idx, worst_fractal_idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuranal simplificada para las 2 caracteristicas\n",
    "\n",
    "\n",
    "es parecida al modelo de la red que configuramos anteriormente pero adaptado para hacer la comparacion , en este caso se cambian estos datos :\n",
    "\n",
    "- Arquitectura: 2 → 16 → 16 → 2 \n",
    "- dropout al 0.2 porque hay menos datos\n",
    "\n",
    "luego en la parte del entrenameinto neuronal como se muestra en el ccomntario del codigo de adapta para lo siguiente:\n",
    "\n",
    "- Convierte los datos de 2 características a tensores\n",
    "- Crea modelo, función de pérdida y optimizador específicos\n",
    "- lr=0.01: Velocidad de aprendizaje más alta \n",
    "- luego en el loop se reduce de 500 a 200 epoocas a menos caracteristicas menos iteraciones, entonces esto simplifica las cosas para la red\n",
    "\n",
    "#### evaluacion final \n",
    "\n",
    "`acc_nn_2feat = accuracy_score(y_test, y_test_pred_2feat.numpy())` aqui basicamnete se calcula accuracy de la red neuronal con solo  las 2 características que habiamos medido para comparar con los resultados de la regresion logistica  implemntada \n",
    "\n",
    "\n",
    "en conclusiion este fragmento nos permite simplificar la red para evaluarla junto con los resultados de la regresion para coparar si esta red neuronal mas simple es mejor o puede ponerse a la par con la regresion logistica usando solo las 2 varible propuestas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=16, output_dim=2, dropout_rate=0.2):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Entrenamiento de red neuronal con 2 características\n",
    "X_train_2feat_tensor = torch.tensor(X_train_2feat, dtype=torch.float32)\n",
    "X_test_2feat_tensor = torch.tensor(X_test_2feat, dtype=torch.float32)\n",
    "\n",
    "model_2feat = SimpleNet()\n",
    "criterion_2feat = nn.CrossEntropyLoss()\n",
    "optimizer_2feat = optim.Adam(model_2feat.parameters(), lr=0.01)\n",
    "\n",
    "# Entrenamiento rápido (200 épocas)\n",
    "for epoch in range(200):\n",
    "    model_2feat.train()\n",
    "    optimizer_2feat.zero_grad()\n",
    "    outputs = model_2feat(X_train_2feat_tensor)\n",
    "    loss = criterion_2feat(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer_2feat.step()\n",
    "\n",
    "# Evaluación red neuronal 2 características\n",
    "model_2feat.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs_2feat = model_2feat(X_test_2feat_tensor)\n",
    "    _, y_test_pred_2feat = torch.max(test_outputs_2feat, 1)\n",
    "    acc_nn_2feat = accuracy_score(y_test, y_test_pred_2feat.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizaulizacion de los resultados\n",
    "\n",
    "aqui basicamente hago los graficos para anlizar resultadoos en este caso se realiza un total de 3 graficos para demostrar el estudio estos fueron: \n",
    "\n",
    "- Grafico 1: CURVA DE PÉRDIDA\n",
    "\n",
    "\n",
    "Eje X: epocas (1 a 500)\n",
    "Eje Y: error del modelo en cada época\n",
    "\n",
    "aqui podemos ver si el modelo está aprendiendo la perdida en la grafica deberia bajar tambien funciona para detectar si se \"atasca\" o aprende demasiado rápido\n",
    "\n",
    "\n",
    "- Grafico 2:  ACCURACY DE ENTRENAMIENTO\n",
    "\n",
    "\n",
    "Eje X: Épocas 10- 500\n",
    "Eje Y: % de predicciones correctas\n",
    "Tendencia esperada: Línea que sube (más accuracy = mejor)\n",
    "\n",
    "\n",
    "- Grafico 3:  MATRIZ DE CONFUSIÓN\n",
    "\n",
    "\n",
    "Cuadro 2x2 que compara predicciones vs realidad:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva de entrenamiento\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Curva de Pérdida Durante Entrenamiento\")\n",
    "plt.xlabel(\"epoca\")\n",
    "plt.ylabel(\"CrossEntropy Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "epochs_acc = range(10, epochs + 1, 10)\n",
    "plt.plot(epochs_acc, accuracy_history)\n",
    "plt.title(\"Accuracy Durante Entrenamiento\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Matriz de confusión\n",
    "plt.subplot(1, 3, 3)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Maligno\", \"Benigno\"],\n",
    "    yticklabels=[\"Maligno\", \"Benigno\"],\n",
    ")\n",
    "plt.title(\"Matriz de Confusión - Red Neuronal\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Realidad\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis\n",
    "\n",
    "\n",
    "\n",
    "### curva de perdida:\n",
    "\n",
    "\n",
    "Empieza alto (~1.0) y baja rápidamente luego se estabiliza alrededor de 0.05 después de 100 epocas y ahi la curva ya no presenta mas oscilaciones, lo que se traduce en  que el modelo aprendio correctamente que no hubo un sobreajuste y la convergencia fue rapida pues no se necesito de muchas epocas\n",
    "\n",
    "\n",
    "###  Accuary de entrenamiento \n",
    "\n",
    "\n",
    "Empieza en 50%, subee rápidamente a 100% en las primeras 50 épocas y se mantiene estable cerca del 100% qu es basicamente una alta precisión mantenida durante todo el entrenamiento\n",
    "\n",
    "\n",
    "### matriz de confusion \n",
    "\n",
    "\n",
    "Maligno - Maligno: 41 canceres detectados\n",
    "Maligno - Benigno: 1 cancer no detectado \n",
    "Benigno - Maligno: 4  falsa alarma\n",
    "Benigno - Benigno: 68 sanos correctos\n",
    "\n",
    "Métricas calculadas:\n",
    "\n",
    "Accuracy: (41+68)/114 = 95.6%\n",
    "Solo 5 errores de 114 casos\n",
    "\n",
    "\n",
    "el modelo que se realizao en teoria funciona bien pero ele no detectar un cancer hablkando en situaciones reales puede resultar en un error grave por ende se puede ajustar el modelo , para qeu los detecte aunque puede que lso resultado cambien "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tabla comparativa \n",
    "\n",
    "- results_table = solo creamos la tabla usando rich \n",
    "- results_table.add_column  = son las  columnas a representar en esta tabla Modelo,Características,Precisión. Cada una configurada con posicion y color\n",
    "\n",
    "- results_table.add_row = agrega 4 filas las cuales  usan klas varibles ya definidas anterirormente para  representyar \n",
    "- Regresión Logística: 30 features (97.37%) y 2 features (98.25%)\n",
    "- Red Neuronal: 30 features (95.61%) y 2 features (93.86%)\n",
    "\n",
    "La regresión logística funciono mejor que las redes neuronales en este dataset, especialmente con pocas características.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = Table(\n",
    "    title=\"Comparación: Regresión Logística vs Redes Neuronales\",\n",
    "    show_header=True,\n",
    "    header_style=\"bold\",\n",
    ")\n",
    "\n",
    "results_table.add_column(\"Modelo\", justify=\"left\", style=\"cyan\")\n",
    "results_table.add_column(\"Características\", justify=\"center\", style=\"yellow\")\n",
    "results_table.add_column(\"Precisión\", justify=\"right\", style=\"green\")\n",
    "\n",
    "# Resultados anteriores (baseline)\n",
    "results_table.add_row(\"Regresión Logistica\", \"30 caracteristicas\", f\"{acc_log_all:.4f}\")\n",
    "\n",
    "results_table.add_row(\n",
    "    \"Regresion Logoistica\",\n",
    "    \"worst radius...\\nworst fractal dimensions\",\n",
    "    f\"{acc_log_2feat:.4f}\",\n",
    ")\n",
    "\n",
    "# Nuevos resultados (redes neuronales)\n",
    "results_table.add_row(\"Red Neuronal\", \"30 características\", f\"{acc_test_nn:.4f}\")\n",
    "\n",
    "results_table.add_row(\n",
    "    \"Red Neuronal\", \"worst radius...\\nworst fractal dimensions\", f\"{acc_nn_2feat:.4f}\"\n",
    ")\n",
    "\n",
    "console = Console()\n",
    "console.print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_modelo = max(\n",
    "    [\n",
    "        (\"Reg. Logística (30 feat)\", acc_log_all),\n",
    "        (\"Reg. Logística (2 feat)\", acc_log_2feat),\n",
    "        (\"Red Neuronal (30 feat)\", acc_test_nn),\n",
    "        (\"Red Neuronal (2 feat)\", acc_nn_2feat),\n",
    "    ],\n",
    "    key=lambda x: x[1],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"MEJOR MODELO: {mejor_modelo[0]} con {mejor_modelo[1]:.4f} ({mejor_modelo[1]*100:.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis general \n",
    "\n",
    "en resumen se implemntaron e implementaron dos arquitecturas de redes neuronales una compleja de 30→64→32→16→2 y otra simple de 2→16→16→2 con una tecnica llamda  BatchNorm, Dropout y optimizador Adam, entrenadas durante 500 y 200 épocas respectivamente. Los resultados muestran que la regresión logística 98.25% con 2 características superó a las redes neuronales 95.6% con 30 características y 93.9% con 2, lo qeu nos dice  que modelos simples pueden ser más efectivos en datasets pequeños como este , visualizaciones completas y métricas exhaustivas, aunque presenta 1 falso negativo crítico para aplicaciones médicas, dandom=nos a entender que la simplicidad puede ayudar a una mejor genralizacion que un caomplejidad mas alla como la de una red y su arquitecturta con datos limitado como este dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
