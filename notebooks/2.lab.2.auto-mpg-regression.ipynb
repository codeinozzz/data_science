{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div\n",
    "  style=\"\n",
    "    background-color: #f0f0f0;\n",
    "    color:rgb(56, 56, 56);\n",
    "    padding: 8px;\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    gap: 100px;\n",
    "  \"\n",
    ">\n",
    "  <img src=\"./images/brand.svg\" style=\"max-height: 80px;\">\n",
    "  <strong>\n",
    "    AI Saga: Data Science and Machine Learning</br>\n",
    "    2.lab.2. Auto MPG Regression\n",
    "  </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "You will continue working with the Auto MPG dataset, implementing regression models using scikit-learn.\n",
    "\n",
    "The dataset includes:\n",
    "- 398 instances\n",
    "- 8 attributes including MPG, cylinders, displacement, horsepower, weight, acceleration, model year and origin\n",
    "\n",
    "### Description\n",
    "\n",
    "Your task is to implement regression models using scikit-learn to:\n",
    "\n",
    "- Implement linear regression to predict MPG\n",
    "- Implement polynomial regression with different degrees\n",
    "- Compare the performance of linear vs polynomial models\n",
    "- Visualize the fits for the most relevant feature\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "- A *ipynb* (Jupyter Notebook) file called *auto-mpg-regression.ipynb*\n",
    "- Visualizations comparing linear and polynomial fits\n",
    "- Analysis of model performance for different polynomial degrees\n",
    "- Use the provided template as a starting point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de coorrelacioon \n",
    "\n",
    "\n",
    "Para saber qué variable predice mejor el MPG, calculamos correlaciones entre todas las variables numéricas. Esto pues  nos ayuda a encontrar automáticamente la característica qu es mas importante.\n",
    "\n",
    "\n",
    "\n",
    "- elect_dtypes(include=[np.number]) filtra automáticamente solo las columnas numéricas\n",
    "- corr() calcula la matriz de correlación de Pearson entre todas las variables\n",
    "- sns.heatmap() visualiza la matriz con colores para identificar correlaciones fuertes\n",
    "- abs().sort_values() ordena las correlaciones por valor absoluto para encontrar la más fuerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"RdBu_r\", center=0)\n",
    "plt.title(\"Matriz de Correlación\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " esta  Identifica automáticamente la variable más correlacionada\n",
    "\n",
    " La matriz nos revela que weight tiene la correlación más fuerte con MPG (-0.83), seguido por displacement (-0.81) y cylinders (-0.78). Esta correlación es negativa pero como se toma encunta el valor absoluto de puede indicar que los vehículos más pesados consumen más combustible, lo cual es lógico a mi parecer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_correlations = correlation_matrix[\"mpg\"].abs().sort_values(ascending=False)\n",
    "most_relevant_feature = mpg_correlations.index[1]  # Excluir MPG mismo\n",
    "print(\n",
    "    f\"Variable más correlacionada: {most_relevant_feature} ({mpg_correlations.iloc[1]:.3f})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Visualización de la relación principal\n",
    "\n",
    "-  plt.scatter() crea un gráfico de dispersión para visualizar la relación entre dos variables\n",
    "-  plt.hist() genera histogramas para ver la distribución de una variable individual\n",
    "-  plt.subplot()  permite crear múltiples gráficos en una sola figura\n",
    "\n",
    "Graficamos la relación entre weight y MPG para entender  mejor y visualmente\n",
    "\n",
    "Se observa una clara relación que  no  es lineal entre weight y MPG, Los vehículos ligeros de menos de 2500 lb  muestran gran variabilidad en lo qeu respecta eficiencia 15-45 MPG segun la grafica  mientras que vehículos pesados sde mas de 4000 lbs están concentrados en bajos valores de MPG eentre 10 y 20 en base a eso se define que Existe un punto de inflexión que estaa redondeando on mejor dicho alrededor  de 3000 lbs donde la eficiencia empieza a caer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[most_relevant_feature], df[\"mpg\"], alpha=0.6)\n",
    "plt.xlabel(most_relevant_feature.capitalize())\n",
    "plt.ylabel(\"MPG\")\n",
    "plt.title(f\"Relación entre {most_relevant_feature.capitalize()} y MPG\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Preprocesamiento con Scikit-Learn\n",
    "\n",
    "La normalización aqui  es importante  porque las variables tienen escalas muy diferentes. Por ejemplo, weight puede estar en miles \\ mientras que acceleration está en decenas por ende se hace el preprocesamitno:\n",
    "\n",
    "\n",
    "- train_test_split() divide automáticamente los datos de forma aleatoria\n",
    "- StandardScaler() calcula la media y desviación estándar del conjunto de entrenamiento con fit_transform() y aplica la misma transformación al conjunto de prueba con transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = df[[\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"]]\n",
    "X_single = df[[most_relevant_feature]]\n",
    "y = df[\"mpg\"]\n",
    "\n",
    "# División entrenamiento/prueba con scikit-learn\n",
    "X_multi_train, X_multi_test, X_single_train, X_single_test, y_train, y_test = (\n",
    "    train_test_split(X_multi, X_single, y, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# normalización con scikit-learn\n",
    "scaler_multi = StandardScaler()\n",
    "scaler_single = StandardScaler()\n",
    "\n",
    "X_multi_train_scaled = scaler_multi.fit_transform(X_multi_train)\n",
    "X_multi_test_scaled = scaler_multi.transform(X_multi_test)\n",
    "\n",
    "X_single_train_scaled = scaler_single.fit_transform(X_single_train)\n",
    "X_single_test_scaled = scaler_single.transform(X_single_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de Regresión Lineal Multivariable\n",
    "\n",
    "Utilizo scikit-learn para crear un modelo que usa múltiples características:\n",
    "\n",
    "\n",
    "- LinearRegression() crea el objeto del modelo de regresión lineal\n",
    "- fit() entrena el modelo calculando los coeficientes óptimos usando mínimos cuadrados\n",
    "- predict() genera predicciones usando la ecuación lineal aprendida\n",
    "- mean_squared_error() calcula el error promedio al cuadrado entre predicciones y valores reales\n",
    "- r2_score() mide qué porcentaje de la varianza explica el modelo (0-1, donde 1 es perfecto)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo de regresión lineal multivariable\n",
    "linear_multi = LinearRegression()\n",
    "linear_multi.fit(X_multi_train_scaled, y_train)\n",
    "\n",
    "y_pred_linear_multi = linear_multi.predict(X_multi_test_scaled)\n",
    "mse_linear_multi = mean_squared_error(y_test, y_pred_linear_multi)\n",
    "r2_linear_multi = r2_score(y_test, y_pred_linear_multi)\n",
    "\n",
    "print(\n",
    "    f\"Regresión lineal multivariable - MSE: {mse_linear_multi:.2f},  R^2: {r2_linear_multi:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de Regresión Lineal Univariable\n",
    "\n",
    "Creo un modelo usando únicamente la característica más relevante (weight). Esto nos sirve de baseline para comparar con modelos más complejos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_single = LinearRegression()\n",
    "linear_single.fit(X_single_train_scaled, y_train)\n",
    "\n",
    "# Evaluar rendimiento\n",
    "y_pred_linear_single = linear_single.predict(X_single_test_scaled)\n",
    "mse_linear_single = mean_squared_error(y_test, y_pred_linear_single)\n",
    "r2_linear_single = r2_score(y_test, y_pred_linear_single)\n",
    "\n",
    "print(\n",
    "    f\"Regresión lineal univariable - MSE: {mse_linear_single:.2f}, R^2: {r2_linear_single:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de Regresión Polinomial con diferentes grados\n",
    "\n",
    ">Me basé en el código propuesto en clase para implementar modelos polinomiales: \n",
    "\n",
    "- PolynomialFeatures(degree=degree) transforma automáticamente x en [x, x^2] según el grado\n",
    "- fit_transform() aprende la transformación en entrenamiento y la aplica\n",
    "- transform() aplica la misma transformación polinomial a los datos de prueba\n",
    "- El loop for degree in degrees permite probar múltiples grados automáticamente\n",
    "- Cada modelo se entrena con LinearRegression() pero sobre las características que ya estan  transformadas\n",
    "\n",
    "básicamente, convertimos el problema no lineal en uno lineal al transformar las características esto por que un modelo de grado 2 puede aprender curvas, grado 3 curvas más complejas y asi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [1, 2, 3, 4, 5]\n",
    "polynomial_results = {}\n",
    "\n",
    "for degree in degrees:\n",
    "    # Crear características polinomiales\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly_train = poly_features.fit_transform(X_single_train_scaled)\n",
    "    X_poly_test = poly_features.transform(X_single_test_scaled)\n",
    "\n",
    "    # Entrenar modelo\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X_poly_train, y_train)\n",
    "\n",
    "    # Predicciones y métricas\n",
    "    y_pred_poly = poly_model.predict(X_poly_test)\n",
    "    mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "    r2_poly = r2_score(y_test, y_pred_poly)\n",
    "\n",
    "    polynomial_results[degree] = {\n",
    "        \"model\": poly_model,\n",
    "        \"poly_features\": poly_features,\n",
    "        \"mse\": mse_poly,\n",
    "        \"r2\": r2_poly,\n",
    "        \"y_pred\": y_pred_poly,\n",
    "    }\n",
    "\n",
    "    print(f\"grado {degree} - MSE: {mse_poly:.2f}, R^2: {r2_poly:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación del rendimiento de modelos\n",
    "\n",
    "- pd.DataFrame() organiza todos los resultados en una tabla estructurada\n",
    "- plt.subplots() crea múltiples (2) gráficos lado a lado para comparación\n",
    "- bar() genera gráficos de barras para comparar métricas entre modelos\n",
    "- tick_params(rotation=45) rota las etiquetas del eje x para mejor legibilidad\n",
    "\n",
    "\n",
    " Los resultados muestran que el modelo lineal multivariable supera un poco al univariable, pero ambos tienen limitaciones debido a lo no lineal de los datos. \n",
    " \n",
    " Los modelos polinomiales de grado 2-3 presentan mejoras significativas en R^2 demostrando  que se  capturan mejor la curvatura natural de la relación weight-MPG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Modelo\": [\"Lineal Multi\", \"Lineal Single\"]\n",
    "        + [f\"Polinomial Grado {d}\" for d in degrees],\n",
    "        \"MSE\": [mse_linear_multi, mse_linear_single]\n",
    "        + [polynomial_results[d][\"mse\"] for d in degrees],\n",
    "        \"R²\": [r2_linear_multi, r2_linear_single]\n",
    "        + [polynomial_results[d][\"r2\"] for d in degrees],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"=== Comparación de Modelos ===\")\n",
    "print(results_df.round(3))\n",
    "\n",
    "# Visualiza la comparación\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.bar(results_df[\"Modelo\"], results_df[\"MSE\"], color=\"lightcoral\")\n",
    "ax1.set_title(\"Error Cuadrático Medio (MSE)\")\n",
    "ax1.set_ylabel(\"MSE\")\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "ax2.bar(results_df[\"Modelo\"], results_df[\"R²\"], color=\"lightblue\")\n",
    "ax2.set_title(\"Coeficiente de Determinación (R²)\")\n",
    "ax2.set_ylabel(\"R²\")\n",
    "ax2.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de ajustes para la característica más relevante\n",
    "\n",
    " múltiples subplots para comparar visualmente todos los modelos:\n",
    "\n",
    "\n",
    "- np.linspace() genera puntos uniformemente que son espaciados para crear curvas de predicción\n",
    "- plt.subplot(2, 3, i+1) crea una matriz  o cuadricula de 2x3 gráficos siguiendo el patrón del código propuesto en ,los ejemplos\n",
    "- plt.scatter() muestra los datos reales de prueba\n",
    "- plt.plot() dibuja la línea de predicción del modelo sobre los datos\n",
    "- El loop permite automatizar la visualización de todos los grados polinomiales\n",
    "\n",
    "\n",
    "\n",
    "- ### Grado 1 (Lineal): \n",
    "La línea recta no captura la curvatura natural de los datos, resultando en predicciones no muy conscias o por asi decrrlo nunpco pobres.\n",
    "\n",
    "- ### Grado 2: \n",
    "Muestra una curva que sigue mejor el patrón de los datos, con mejora notable en R^2.\n",
    "\n",
    "- ### Grado 3:\n",
    "\n",
    "Ligera mejora adicional, capturando mejor los matices de la relación no lineal.\n",
    "\n",
    "- ### Grados  4-5:\n",
    " Presenta oscilaciones en los extremos, indicando sobreajuste  en los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Crear datos para curva suave de predicción\n",
    "X_plot = np.linspace(X_single_train.min(), X_single_train.max(), 300).reshape(-1, 1)\n",
    "X_plot_scaled = scaler_single.transform(X_plot)\n",
    "\n",
    "for i, degree in enumerate([1, 2, 3, 4, 5]):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "\n",
    "    # datos de prueba\n",
    "    plt.scatter(X_single_test, y_test, alpha=0.6, s=30)\n",
    "\n",
    "    if degree == 1:\n",
    "        # Predicción lineal\n",
    "        y_plot = linear_single.predict(X_plot_scaled)\n",
    "        mse_show = mse_linear_single\n",
    "        r2_show = r2_linear_single\n",
    "    else:\n",
    "        # predicción polinomial\n",
    "        poly_features = polynomial_results[degree][\"poly_features\"]\n",
    "        X_plot_poly = poly_features.transform(X_plot_scaled)\n",
    "        y_plot = polynomial_results[degree][\"model\"].predict(X_plot_poly)\n",
    "        mse_show = polynomial_results[degree][\"mse\"]\n",
    "        r2_show = polynomial_results[degree][\"r2\"]\n",
    "\n",
    "    plt.plot(X_plot, y_plot, \"r-\", linewidth=2)\n",
    "    plt.title(f\"Grado {degree}\\nMSE: {mse_show:.1f}, R²: {r2_show:.3f}\")\n",
    "    plt.xlabel(most_relevant_feature.capitalize())\n",
    "    plt.ylabel(\"MPG\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación del mejor modelo\n",
    "\n",
    "pandas para automatizar la selección del modelo óptimo:\n",
    "\n",
    "- idxmax() encuentra automáticamente el índice del valor máximo en la columna R^2\n",
    "- loc[] selecciona la fila completa correspondiente al mejor modelo\n",
    "- Esto nos da una recomendación objetiva basada en métricas numéricas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = results_df[\"R²\"].idxmax()\n",
    "best_model = results_df.loc[best_idx]\n",
    "\n",
    "print(f\"Modelo: {best_model['Modelo']}\")\n",
    "print(f\"MSE: {best_model['MSE']:.2f}\")\n",
    "print(f\"R^2: {best_model['R²']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion final\n",
    "\n",
    "El análisis revela que la regresión polinomial de grado 2-3 es mejor  para predecir MPG basado en el peso del vehículo\n",
    "\n",
    "**Hallazgos**\n",
    "\n",
    "\n",
    "1. Weight es la variable más predictiva con correlación con MPG\n",
    "2. La relación es claramente no lineal, con un punto de inflexión alrededor de 3000 lbs\n",
    "3. Modelos polinomiales grado 2-3 ofrecen el mejor balance entre precisión y simplicidad\n",
    "4. Grados superiores (4-5) muestran sobreajuste sin beneficio realmente bueno o signbificativo\n",
    "5. Variables múltiples mejoran  la predicción\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
